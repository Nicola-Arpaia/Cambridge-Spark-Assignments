{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling - ADS09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, you will be working with a collection of articles on topics, including baseball, cryptography, electronics, hardware, medicine, mideast, motorcycles, politics, religion, and space. The posts are extracted from the 20 Newsgroups dataset.\n",
    "\n",
    "Your tasks in this assignment will include preprocessing this data, and predicting the topics from this collection of texts using a supervised machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sidetable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/X_train.csv\")\n",
    "labels = pd.read_csv(\"data/y_train.csv\")\n",
    "test = pd.read_csv(\"data/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>csc2imd@cabell.vcu.edu (Ian M. Derby) writes:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In &lt;30MAR93.02086551.0010@MUSIC.LIB.MATC.EDU P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In article &lt;15780004@hpspdla.spd.HP.COM garyr@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi, baseball fans! So what do you say? Don't y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In article &lt;93104.233239ISSBTL@BYUVM.BITNET, &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NOTE: Saturday, April 20th's scores should be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Does that mean they have to pay his salary?  D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In &lt;1993Apr19.194025.8967@adobe.com snichols@a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In article &lt;1qkkodINN5f5@jhunix.hcf.jhu.edu pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In article &lt;C5p6xq.GuI@me.utoronto.ca steinman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  csc2imd@cabell.vcu.edu (Ian M. Derby) writes:\\...\n",
       "1  In <30MAR93.02086551.0010@MUSIC.LIB.MATC.EDU P...\n",
       "2  In article <15780004@hpspdla.spd.HP.COM garyr@...\n",
       "3  Hi, baseball fans! So what do you say? Don't y...\n",
       "4  In article <93104.233239ISSBTL@BYUVM.BITNET, <...\n",
       "5  NOTE: Saturday, April 20th's scores should be ...\n",
       "6  Does that mean they have to pay his salary?  D...\n",
       "7  In <1993Apr19.194025.8967@adobe.com snichols@a...\n",
       "8  In article <1qkkodINN5f5@jhunix.hcf.jhu.edu pa...\n",
       "9  In article <C5p6xq.GuI@me.utoronto.ca steinman..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6384, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train.head(10))\n",
    "train.shape\n",
    "#(train.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create numeric labels for the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label         label_num\n",
       "baseball      0            570\n",
       "cryptography  1            652\n",
       "electronics   2            596\n",
       "hardware      3            580\n",
       "medicine      4            596\n",
       "mideast       5            606\n",
       "motorcycles   6            661\n",
       "politics      7            770\n",
       "religion      8            736\n",
       "space         9            617\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "labels['label_num'] = le.fit_transform(labels['label'])\n",
    "labels.groupby(['label','label_num']).label.agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 classifications and the dataset is well balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing - First Pass\n",
    "Here we have defined a function that will do some standard data cleaning and lemmatise the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy model \n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def preprocess(text, lemmatise, pos = None):\n",
    "    # Basic Preprocessing\n",
    "    text = text.lower() #makes lower case\n",
    "    text = re.sub('[\\w-]+@([\\w-]+\\.)+[\\w-]+', '', text)  # remove words with @\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # removes punctuation\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) #removes words with numbers\n",
    "    text = re.sub('/(\\r\\n)+|\\r+|\\n+|\\t+/i', ' ', text) #removes carriage returns line breas tabs replace wuith space\n",
    "\n",
    "    #pass through spacy model\n",
    "    nlp_text = nlp(text)\n",
    "    \n",
    "    if lemmatise == 'on':\n",
    "        if pos == None:\n",
    "            lemmas = [token.lemma_ for token in nlp_text if token.lemma_ !='-PRON-']\n",
    "        else: \n",
    "            lemmas = [token.lemma_ for token in nlp_text if token.pos_ in pos]    \n",
    "        return ' '.join(lemmas)\n",
    "    \n",
    "    else: \n",
    "        if pos == None:        \n",
    "            return  nlp_text\n",
    "        else:\n",
    "            return [token for token in nlp_text if token.pos_==pos]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemm</th>\n",
       "      <th>nounadjverb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>csc2imd@cabell.vcu.edu (Ian M. Derby) writes:\\...</td>\n",
       "      <td>ian m derby write since someone bring up spo...</td>\n",
       "      <td>write bring sport radio sportswrite happen big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In &lt;30MAR93.02086551.0010@MUSIC.LIB.MATC.EDU P...</td>\n",
       "      <td>in   pfan   write for those of who know who be...</td>\n",
       "      <td>write know s team mascot will give walking pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In article &lt;15780004@hpspdla.spd.HP.COM garyr@...</td>\n",
       "      <td>in article    gary rosen write thomas miller  ...</td>\n",
       "      <td>article write think weekend strange one strang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi, baseball fans! So what do you say? Don't y...</td>\n",
       "      <td>hi baseball fan so what do say do not think de...</td>\n",
       "      <td>baseball fan say think deserve mean consider g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In article &lt;93104.233239ISSBTL@BYUVM.BITNET, &lt;...</td>\n",
       "      <td>in article    write i would like to make every...</td>\n",
       "      <td>article write would like make aware win lead g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                                               lemm                                        nounadjverb\n",
       "0  csc2imd@cabell.vcu.edu (Ian M. Derby) writes:\\...    ian m derby write since someone bring up spo...  write bring sport radio sportswrite happen big...\n",
       "1  In <30MAR93.02086551.0010@MUSIC.LIB.MATC.EDU P...  in   pfan   write for those of who know who be...  write know s team mascot will give walking pap...\n",
       "2  In article <15780004@hpspdla.spd.HP.COM garyr@...  in article    gary rosen write thomas miller  ...  article write think weekend strange one strang...\n",
       "3  Hi, baseball fans! So what do you say? Don't y...  hi baseball fan so what do say do not think de...  baseball fan say think deserve mean consider g...\n",
       "4  In article <93104.233239ISSBTL@BYUVM.BITNET, <...  in article    write i would like to make every...  article write would like make aware win lead g..."
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the preprocessing function first just lemmatise and secondly returning noun/ verb/adj\n",
    "train['lemm'] = train['text'].apply(lambda x: preprocess(x, 'on')) \n",
    "train['nounadjverb'] = train['text'].apply(lambda x: preprocess(x, 'on', ['NOUN','VERB','ADJ'])) \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction\n",
    "Here we will convert the text into word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "# create a function that vectorises the data using tfidf\n",
    "def text2vec(train, test):\n",
    "    tfidf = TfidfVectorizer(stop_words=stop_words, ngram_range = (1,1), max_df = 0.7)\n",
    "    train_transformed = tfidf.fit_transform(train)\n",
    "    test_transformed = tfidf.transform(test)\n",
    "    return tfidf,train_transformed, test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorise using the preprocessor (lemmatise only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer, vectors_train, vectors_test = text2vec(X_train['lemm'].tolist(), X_test['lemm'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data format:  (5107, 37325)   Non-zero components estimate:  77.54944194243195\n",
      "Test Data format:   (1277, 37325)   Non-zero components estimate:  73.23805794831637\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain Data format:  {}   Non-zero components estimate:  {}\".format(vectors_train.shape,vectors_train.nnz / float(vectors_train.shape[0])))\n",
    "print(\"Test Data format:   {}   Non-zero components estimate:  {}\".format(vectors_test.shape,vectors_test.nnz / float(vectors_test.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classify and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top10(classifier, categories, vectorizer):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(sorted(categories)):\n",
    "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "def classify(categories, vectorizer, vectors_train, vectors_test, train_set,  clf):\n",
    "    clf.fit(vectors_train, train_set)\n",
    "    predictions = clf.predict(vectors_test)\n",
    "    show_top10(clf, categories, vectorizer)\n",
    "    return clf.predict(vectors_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseball: fan pitch run hit player win baseball year team game\n",
      "cryptography: escrow algorithm nsa phone use clipper government encryption chip key\n",
      "electronics: amp good output voltage power line work battery circuit use\n",
      "hardware: problem monitor disk bus use ide controller scsi card drive\n",
      "medicine: gordon cause medical know article patient disease doctor food msg\n",
      "mideast: armenian say article jewish people turkish arab jews israeli israel\n",
      "motorcycles: bmw helmet rider like dog motorcycle article ride dod bike\n",
      "politics: just make say right clayton man homosexual government article people\n",
      "religion: moral morality value people article jesus theory objective say god\n",
      "space: pat like shuttle article nasa just orbit moon launch space\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    baseball       0.99      1.00      1.00       136\n",
      "cryptography       0.96      0.99      0.98       130\n",
      " electronics       0.94      0.90      0.92       120\n",
      "    hardware       0.92      0.93      0.93       102\n",
      "    medicine       0.98      0.95      0.96       114\n",
      "     mideast       0.79      0.91      0.85       113\n",
      " motorcycles       1.00      0.99      0.99       139\n",
      "    politics       0.76      0.69      0.72       156\n",
      "    religion       0.85      0.83      0.84       149\n",
      "       space       0.97      1.00      0.98       118\n",
      "\n",
      "    accuracy                           0.91      1277\n",
      "   macro avg       0.92      0.92      0.92      1277\n",
      "weighted avg       0.91      0.91      0.91      1277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cats = sorted(labels['label'].value_counts().index.to_list())\n",
    "# Create test prediction\n",
    "test_pred = classify(cats,vectorizer, vectors_train, vectors_test, y_train['label_num'],  clf=MultinomialNB(alpha=.01))\n",
    "print(classification_report( y_test['label_num'], test_pred, target_names=cats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Improvements\n",
    "The base model gives an accuracy of 91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just compare with Standard Linear SVC\n",
    "accuracy 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseball: pitcher career phillies season cub hit player team game baseball\n",
      "cryptography: des encrypt pgp wiretap sternlight security nsa encryption clipper key\n",
      "electronics: amp input battery cool audio tv radar copy voltage circuit\n",
      "hardware: disk bio cache modem motherboard computer monitor pc drive card\n",
      "medicine: food medicine treatment needle pain gordon msg medical doctor disease\n",
      "mideast: jewish armenian turkey policy zionism jews turkish arab israel israeli\n",
      "motorcycles: ama honda rider dog helmet bmw motorcycle ride bike dod\n",
      "politics: william child drieux deficit liberal cramer homosexual clayton kaldis gay\n",
      "religion: beast koresh odwyer god objective universe moral bible mormons christian\n",
      "space: earth sky moon orbit scispace shuttle launch nasa pat space\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    baseball       0.98      1.00      0.99       136\n",
      "cryptography       0.98      0.98      0.98       130\n",
      " electronics       0.96      0.94      0.95       120\n",
      "    hardware       0.93      0.95      0.94       102\n",
      "    medicine       0.97      0.95      0.96       114\n",
      "     mideast       0.80      0.80      0.80       113\n",
      " motorcycles       0.99      0.99      0.99       139\n",
      "    politics       0.69      0.70      0.70       156\n",
      "    religion       0.83      0.83      0.83       149\n",
      "       space       0.96      0.97      0.96       118\n",
      "\n",
      "    accuracy                           0.90      1277\n",
      "   macro avg       0.91      0.91      0.91      1277\n",
      "weighted avg       0.90      0.90      0.90      1277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = classify(cats, vectorizer, vectors_train, vectors_test, y_train['label_num'],  clf=LinearSVC())\n",
    "print(classification_report( y_test['label_num'], test_pred, target_names=cats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a pipeline and combine with gridsearch cv\n",
    "Best Score 0.913 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.913\n",
      "{'clf__alpha': 0.01, 'tfidf_vectorizer__max_df': 0.8, 'tfidf_vectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('tfidf_vectorizer', TfidfVectorizer(stop_words = stop_words)),\n",
    "                     ('clf', MultinomialNB())\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(X_train['lemm'].tolist(), y_train['label_num'])\n",
    "test_pred = text_clf.predict(X_test['lemm'].tolist())\n",
    "\n",
    "parameteres = { 'tfidf_vectorizer__ngram_range' : [(1, 1), (1, 2)],\n",
    "                'tfidf_vectorizer__max_df' : [0.5, 0.8, 1.0],\n",
    "               'clf__alpha':[0.1, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(text_clf, param_grid=parameteres, cv=5)\n",
    "grid.fit(X_train['lemm'].tolist(), y_train['label_num'])\n",
    "print (\"score = %3.3f\" %(grid.score(X_test['lemm'].tolist(),y_test['label_num'])))\n",
    "print (grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------- \n",
    "# Version 2.0 without Spacy\n",
    "Now going to try without Spacy due to issues submitting to KATE when using spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a Preprocess \n",
    "Remove Spacy from the preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text,):\n",
    "    # Bsic Preprocessing\n",
    "    #Make text lowercase, remove punctuation and remove words containing numbers and email addresses\n",
    "    text = text.lower() #makes lower case\n",
    "    text = re.sub('[\\w-]+@([\\w-]+\\.)+[\\w-]+', '', text)  # remove words with @\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # removes punctuation\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) #removes words with numbers\n",
    "    text = re.sub('/(\\r\\n)+|\\r+|\\n+|\\t+/i', ' ', text) #removes carriage returns line breas tabs replace wuith space\n",
    "    return text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the preprocess function on the dataframe and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['processed'] = train['text'].apply(lambda x: preprocess(x)) \n",
    "train.head()\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b GridSearch \n",
    "Repeat the gridsearch with the new processed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.915\n",
      "{'clf__alpha': 0.01, 'tfidf_vectorizer__max_df': 0.5, 'tfidf_vectorizer__max_features': None, 'tfidf_vectorizer__ngram_range': (1, 2), 'tfidf_vectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('tfidf_vectorizer', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB())\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(X_train['processed'].tolist(), y_train['label_num'])\n",
    "test_pred = text_clf.predict(X_test['processed'].tolist())\n",
    "\n",
    "parameteres = { 'tfidf_vectorizer__ngram_range' : [(1, 1), (1,2)],\n",
    "                'tfidf_vectorizer__max_df' : [.5,  .8,  1.0],\n",
    "                'tfidf_vectorizer__stop_words' :['english', None],\n",
    "                'tfidf_vectorizer__max_features': (None, 5000, 10000),\n",
    "                'clf__alpha':[0.01, 0.1]}\n",
    "\n",
    "grid = GridSearchCV(text_clf, param_grid=parameteres, cv=5)\n",
    "grid.fit(X_train['processed'].tolist(), y_train['label_num'])\n",
    "print (\"score = %3.3f\" %(grid.score(X_test['processed'].tolist(),y_test['label_num'])))\n",
    "print (grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit using the best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    baseball       1.00      1.00      1.00       136\n",
      "cryptography       0.98      1.00      0.99       130\n",
      " electronics       0.95      0.96      0.95       120\n",
      "    hardware       0.95      0.94      0.95       102\n",
      "    medicine       0.99      0.96      0.97       114\n",
      "     mideast       0.80      0.84      0.82       113\n",
      " motorcycles       1.00      0.99      0.99       139\n",
      "    politics       0.74      0.71      0.72       156\n",
      "    religion       0.82      0.85      0.83       149\n",
      "       space       0.97      0.97      0.97       118\n",
      "\n",
      "    accuracy                           0.92      1277\n",
      "   macro avg       0.92      0.92      0.92      1277\n",
      "weighted avg       0.92      0.92      0.92      1277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrain  with the best parameters\n",
    "\n",
    "text_clf = Pipeline([('tfidf_vectorizer', TfidfVectorizer(max_df = 0.5, stop_words = 'english', ngram_range= (1, 2))),\n",
    "                     ('clf', MultinomialNB(alpha = 0.01))\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(X_train['processed'].tolist(), y_train['label_num'])\n",
    "test_pred = text_clf.predict(X_test['processed'].tolist())\n",
    "\n",
    "print(classification_report( y_test['label_num'], test_pred, target_names=cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spacy]",
   "language": "python",
   "name": "conda-env-spacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
