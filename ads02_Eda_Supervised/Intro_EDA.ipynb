{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_processor(df, replacement_str):\n",
    "    \"\"\"\n",
    "    Take a DataFrame and return one where all occurrences\n",
    "    of the replacement string have been replaced by `np.nan`\n",
    "    and, subsequently, all rows containing np.nan\n",
    "    have been removed.\n",
    "\n",
    "    Example with replacement_str='blah'\n",
    "         A       B      C                   A     B    C\n",
    "    --------------------------         ------------------\n",
    "    0 |  0.5 |  0.3   | 'blah'         1 | 0.2 | 0.1 | 5\n",
    "    1 |  0.2 |  0.1   |   5     -->    3 | 0.7 | 0.2 | 1\n",
    "    2 |  0.1 | 'blah' |   3\n",
    "    3 |  0.7 |  0.2   |   1\n",
    "\n",
    "    Note: keep the original index (not reset)\n",
    "\n",
    "    :param df: Input data frame (pandas.DataFrame)\n",
    "    :param replacement_str: string to find and replace by np.nan\n",
    "    :returns: DataFrame where the occurences of replacement_str have been\n",
    "        replaced by np.nan and subsequently all rows containing np.nan have\n",
    "        been removed\n",
    "    \"\"\"\n",
    "    replaced_df = df.replace(replacement_str, np.nan).dropna()\n",
    "    # return replaced_df.astype(float, errors='ignore')\n",
    "    return replaced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cleaner(df, low, high):\n",
    "    \"\"\"\n",
    "    Take a dataframe where columns are all numerical and non-constant.\n",
    "    For each feature, mark the values that are not between the given\n",
    "    percentiles (low-high) as np.nan. If a value is exactly on the high or low\n",
    "    percentile, it should be marked as nan too.\n",
    "\n",
    "    Then, remove all rows containing np.nan.\n",
    "    Finally, the columns must be scaled to have zero mean and unit variance\n",
    "    (do this without sklearn).\n",
    "\n",
    "    Example testdf:\n",
    "            0     1     2\n",
    "    ---------------------\n",
    "    A |   0.1   0.2   0.1\n",
    "    B |   5.0  10.0  20.0\n",
    "    C |   0.2   0.3   0.5\n",
    "    D |   0.3   0.2   0.7\n",
    "    E |  -0.1  -0.2  -0.4\n",
    "    F |   0.1   0.4   0.3\n",
    "    G |  -0.5   0.3  -0.2\n",
    "    H | -10.0   0.3   1.0\n",
    "\n",
    "    Output of feature_cleaner(testdf, 0.01, 0.99):\n",
    "\n",
    "                0         1         2\n",
    "    ---------------------------------\n",
    "    A |  0.191663 -0.956183 -0.515339\n",
    "    C |  0.511101  0.239046  0.629858\n",
    "    D |  0.830540 -0.956183  1.202457\n",
    "    F |  0.191663  1.434274  0.057260\n",
    "    G | -1.724967  0.239046 -1.374236\n",
    "\n",
    "    :param df:      Input DataFrame (with numerical columns)\n",
    "    :param low:     Lowest percentile  (0.0<low<1.0)\n",
    "    :param high:    Highest percentile (low<high<1.0)\n",
    "    :returns:       Scaled DataFrame where elements that are outside of the\n",
    "                    desired percentile range have been removed\n",
    "    \"\"\"\n",
    "    low_ptile = df.quantile(q=low)\n",
    "    high_ptile = df.quantile(q=high)\n",
    "    filtered_df = df[(df > low_ptile) & (df < high_ptile)].dropna()\n",
    "\n",
    "    col_mean = filtered_df.mean(axis=0)\n",
    "    col_var = filtered_df.var(axis=0)\n",
    "    scaled_df = (filtered_df - col_mean)/(col_var**.5)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(df):\n",
    "    \"\"\"\n",
    "    Take a dataframe where all columns are numerical (no NaNs) and not constant\n",
    "    One of the column named \"CLASS\" is either 0 or 1.\n",
    "\n",
    "    Within each class, for each feature compute the ratio (R) of the\n",
    "    range over the variance (the range is the gap between the smallest\n",
    "    and largest value).\n",
    "\n",
    "    For each feature you now have two R; R_0 and R_1 where:\n",
    "        R_0 = (max_class0 - min_class0) / variance_class0\n",
    "\n",
    "    For each column, compute the ratio (say K) of the larger R to the smaller R\n",
    "    Return the name of the column for which this last ratio K is largest.\n",
    "\n",
    "    Test input\n",
    "           A     B     C   CLASS\n",
    "    ----------------------------\n",
    "    0 |  0.1   0.2   0.1     0\n",
    "    1 |  5.0  10.0  20.0     0\n",
    "    2 |  0.2   0.3   0.5     1\n",
    "    3 |  0.3   0.2   0.7     0\n",
    "    4 |\t-0.1  -0.2  -0.4     1\n",
    "    5 |\t 0.1   0.4   0.3     0\n",
    "    6 |\t-0.5   0.3  -0.2     0\n",
    "\n",
    "    Expected output: 'C'\n",
    "\n",
    "    :param df:  Input DataFrame (with numerical columns)\n",
    "    :returns:   Name of the column with largest K\n",
    "    \"\"\"\n",
    "\n",
    "    min_df = df.groupby('CLASS').min()\n",
    "    max_df = df.groupby('CLASS').max()\n",
    "    var_df = df.groupby('CLASS').var()\n",
    "    rval = (max_df - min_df) / var_df\n",
    "    ratio = rval.max()/rval.min()\n",
    "    column = ratio.idxmax(axis=1)\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(label_to_encode, labels):\n",
    "    \"\"\"\n",
    "    Write a function that takes in a label to encode and a list of possible\n",
    "    labels. It should return the label one-hot-encoded as a list of elements\n",
    "    containing 0s and a unique 1 at the index corresponding to the matching\n",
    "    label. Note that the input list of labels should contain unique elements.\n",
    "    If the label does not appear in our known labels, return a list of 0s.\n",
    "\n",
    "    Examples:\n",
    "    one_hot_encode(\"pink\", [\"blue\", \"red\", \"pink\", \"yellow\"]) -> [0, 0, 1, 0]\n",
    "    one_hot_encode(\"b\", [\"a\", \"b\", \"c\", \"d\", \"e\"]) -> [0, 1, 0, 0, 0]\n",
    "    one_hot_encode(\"f\", [\"a\", \"b\", \"c\", \"d\", \"e\"]) -> [0, 0, 0, 0, 0]\n",
    "\n",
    "    :param label_to_encode: the label to encode\n",
    "    :param labels: a list of all possible labels\n",
    "    :return: a list of 0s and one 1\n",
    "    \"\"\"\n",
    "\n",
    "    return [int(i == label_to_encode) for i in labels]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
